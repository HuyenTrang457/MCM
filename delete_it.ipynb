{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzLrRCLiQJRMIkCMotC5tV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenTrang457/MCM/blob/main/model1_momentum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tải các thư viện cần thiết"
      ],
      "metadata": {
        "id": "zhcKe7R6mSO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8RX8BfNeOYH"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y scikit-learn\n",
        "!pip install scikit-learn==1.3.1\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, log_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sử dụng bộ dữ liệu lấy từ phần Data-processing, sau đó chọn ra các cột cần thiết là 'p1_games','point_victor','p1_ace','p1_winner','p1_unf_err' 'p1_distance_run', 'rally_count', 'speed_mph','p1_net_pt_won'. Sau đó tách bộ dữ liệu thành 30 bộ dữ liệu nhỏ ứng với từng match_id, lưu thành file csv mới với tên trùng với match_id\n"
      ],
      "metadata": {
        "id": "ok_tVyFzmtuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bổ sung code tách dữ liệu\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the processed dataset\n",
        "data_path = \"processed_data.csv\"  # Replace with your actual processed data file path\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Select necessary columns\n",
        "columns_to_select = ['match_id', 'p1_games', 'point_victor', 'p1_ace', 'p1_winner', 'p1_unf_err',\n",
        "                     'p1_distance_run', 'rally_count', 'speed_mph', 'p1_net_pt_won']\n",
        "df = df[columns_to_select]\n",
        "\n",
        "# Create a directory to save individual match files\n",
        "output_dir = \"match_files\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Split the dataset by match_id and save each as a separate CSV file\n",
        "unique_match_ids = df['match_id'].unique()\n",
        "\n",
        "for match_id in unique_match_ids:\n",
        "    match_data = df[df['match_id'] == match_id]\n",
        "    match_file_name = f\"{match_id}.csv\"\n",
        "    match_file_path = os.path.join(output_dir, match_file_name)\n",
        "    match_data.to_csv(match_file_path, index=False)\n",
        "\n",
        "print(f\"Files saved in the folder: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "YQ61VEH3or63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đường dẫn tới thư mục chứa các file dataset\n",
        "data_dir = '/content/'\n",
        "\n",
        "# Liệt kê các file trong thư mục (điều chỉnh tên file theo cấu trúc thực tế)\n",
        "file_list = [\n",
        "    '2023-wimbledon-1301.csv',\n",
        "    '2023-wimbledon-1302.csv',\n",
        "    '2023-wimbledon-1303.csv',\n",
        "    '2023-wimbledon-1304.csv',\n",
        "    '2023-wimbledon-1306.csv',\n",
        "    '2023-wimbledon-1307.csv',\n",
        "    '2023-wimbledon-1308.csv',\n",
        "    '2023-wimbledon-1310.csv',\n",
        "    '2023-wimbledon-1311.csv',\n",
        "    '2023-wimbledon-1312.csv',\n",
        "    '2023-wimbledon-1313.csv',\n",
        "    '2023-wimbledon-1314.csv',\n",
        "    '2023-wimbledon-1315.csv',\n",
        "    '2023-wimbledon-1316.csv',\n",
        "    '2023-wimbledon-1401.csv',\n",
        "    '2023-wimbledon-1402.csv',\n",
        "    '2023-wimbledon-1403.csv',\n",
        "    '2023-wimbledon-1404.csv',\n",
        "    '2023-wimbledon-1405.csv',\n",
        "    '2023-wimbledon-1406.csv',\n",
        "    '2023-wimbledon-1407.csv',\n",
        "    '2023-wimbledon-1408.csv',\n",
        "    '2023-wimbledon-1501.csv',\n",
        "    '2023-wimbledon-1502.csv',\n",
        "    '2023-wimbledon-1503.csv',\n",
        "    '2023-wimbledon-1504.csv',\n",
        "    '2023-wimbledon-1601.csv',\n",
        "    '2023-wimbledon-1602.csv',\n",
        "    '2023-wimbledon-1701.csv'\n",
        "]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nm_Mc2QYmYHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Danh sách DataFrame cho từng file\n",
        "dataframes = []\n",
        "\n",
        "for file in file_list:\n",
        "    file_path = f\"{data_dir}/{file}\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    df = df[columns]\n",
        "    df['point_victor'] = df['point_victor'].replace(2, 0)\n",
        "\n",
        "\n",
        "if dataframes:\n",
        "    combined_data = pd.concat(dataframes, ignore_index=True)\n",
        "    # Tách X và y\n",
        "    X = combined_data[['p1_games', 'p1_ace', 'p1_winner', 'p1_unf_err',\n",
        "                       'p1_distance_run', 'rally_count', 'speed_mph','p1_net_pt_won']]\n",
        "    y = combined_data['point_victor']\n",
        "\n",
        "    # Chia thành tập train và test (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "else:\n",
        "    print(\"No data available after filtering!\")"
      ],
      "metadata": {
        "id": "XAqlwGyLqJoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
