{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz43snJ4q6R+yvrRnt24ZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenTrang457/MCM/blob/main/model2_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tải các thư viện cần thiết"
      ],
      "metadata": {
        "id": "zhcKe7R6mSO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8RX8BfNeOYH"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y scikit-learn\n",
        "!pip install scikit-learn==1.3.1\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, log_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sử dụng bộ dữ liệu lấy từ phần Data-processing, sau đó chọn ra các cột cần thiết là 'p1_games','point_victor','p1_ace','p1_winner','p1_unf_err' 'p1_distance_run', 'rally_count', 'speed_mph','p1_net_pt_won'. Sau đó tách bộ dữ liệu thành 30 bộ dữ liệu nhỏ ứng với từng match_id, lưu thành file csv mới với tên trùng với match_id\n"
      ],
      "metadata": {
        "id": "ok_tVyFzmtuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bổ sung code tách dữ liệu\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the processed dataset\n",
        "data_path = \"processed_data.csv\"  # Replace with your actual processed data file path\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Select necessary columns\n",
        "columns_to_select = ['match_id', 'p1_games', 'point_victor', 'p1_ace', 'p1_winner', 'p1_unf_err',\n",
        "                     'p1_distance_run', 'rally_count', 'speed_mph', 'p1_net_pt_won']\n",
        "df = df[columns_to_select]\n",
        "\n",
        "# Create a directory to save individual match files\n",
        "output_dir = \"match_files\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Split the dataset by match_id and save each as a separate CSV file\n",
        "unique_match_ids = df['match_id'].unique()\n",
        "\n",
        "for match_id in unique_match_ids:\n",
        "    match_data = df[df['match_id'] == match_id]\n",
        "    match_file_name = f\"{match_id}.csv\"\n",
        "    match_file_path = os.path.join(output_dir, match_file_name)\n",
        "    match_data.to_csv(match_file_path, index=False)\n",
        "\n",
        "print(f\"Files saved in the folder: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "YQ61VEH3or63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đường dẫn tới thư mục chứa các file dataset\n",
        "data_dir = '/content/'\n",
        "\n",
        "# Liệt kê các file trong thư mục (điều chỉnh tên file theo cấu trúc thực tế)\n",
        "file_list = [\n",
        "    '2023-wimbledon-1301.csv',\n",
        "    '2023-wimbledon-1302.csv',\n",
        "    '2023-wimbledon-1303.csv',\n",
        "    '2023-wimbledon-1304.csv',\n",
        "    '2023-wimbledon-1306.csv',\n",
        "    '2023-wimbledon-1307.csv',\n",
        "    '2023-wimbledon-1308.csv',\n",
        "    '2023-wimbledon-1310.csv',\n",
        "    '2023-wimbledon-1311.csv',\n",
        "    '2023-wimbledon-1312.csv',\n",
        "    '2023-wimbledon-1313.csv',\n",
        "    '2023-wimbledon-1314.csv',\n",
        "    '2023-wimbledon-1315.csv',\n",
        "    '2023-wimbledon-1316.csv',\n",
        "    '2023-wimbledon-1401.csv',\n",
        "    '2023-wimbledon-1402.csv',\n",
        "    '2023-wimbledon-1403.csv',\n",
        "    '2023-wimbledon-1404.csv',\n",
        "    '2023-wimbledon-1405.csv',\n",
        "    '2023-wimbledon-1406.csv',\n",
        "    '2023-wimbledon-1407.csv',\n",
        "    '2023-wimbledon-1408.csv',\n",
        "    '2023-wimbledon-1501.csv',\n",
        "    '2023-wimbledon-1502.csv',\n",
        "    '2023-wimbledon-1503.csv',\n",
        "    '2023-wimbledon-1504.csv',\n",
        "    '2023-wimbledon-1601.csv',\n",
        "    '2023-wimbledon-1602.csv',\n",
        "    '2023-wimbledon-1701.csv'\n",
        "]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nm_Mc2QYmYHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1: Import Libraries and Load Data**\n"
      ],
      "metadata": {
        "id": "-MONlE_6xl_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss\n",
        "import os"
      ],
      "metadata": {
        "id": "uh2mOYSaxeOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load dữ liệu và chuẩn bị bộ dữ liệu để test model**\n",
        "\n",
        "Chia dữ liệu thành hai phần:\n",
        "\n",
        "  Tập huấn luyện (X_train, y_train): Dùng để huấn luyện mô hình (80% dữ liệu).\n",
        "\n",
        "  Tập kiểm tra (X_test, y_test): Dùng để kiểm tra hiệu quả của mô hình (20% dữ  \n",
        "    liệu).\n"
      ],
      "metadata": {
        "id": "Yf-LSiz9yJOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the processed dataset\n",
        "data_path = \"processed_data.csv\"  # Replace with your actual processed data file path\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        " # Split into train and test sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "sg1GDKh1xvL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3: Huấn luyện từng mô hình**\n",
        "\n",
        "Dùng tập huấn luyện để \"dạy\" các mô hình dự đoán kết quả\n",
        "\n",
        "\n",
        "*   Duyệt qua từng mô hình trong danh sách models.\n",
        "* Đánh giá từng mô hình: Đo lường hiệu quả của từng mô hình qua các chỉ số:\n",
        "\n",
        "Accuracy: Tỷ lệ dự đoán đúng.\n",
        "\n",
        "Log Loss: Đo độ chính xác của xác suất dự đoán.\n",
        "\n",
        "Precision: Độ chính xác của các dự đoán thắng.\n",
        "\n",
        "Recall: Tỷ lệ tìm đúng các trường hợp thắng thực tế.\n",
        "\n",
        "F1-Score: Trung bình hài hòa giữa Precision và Recall.\n",
        "\n",
        "ROC-AUC: Diện tích dưới đường cong ROC.\n",
        "\n",
        "Brier Score: Độ sai lệch của xác suất dự đoán.\n"
      ],
      "metadata": {
        "id": "AxC77wmsyaTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Part 3\n",
        "    # Initialize models\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "        \"SVM\": SVC(probability=True, random_state=42),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "        \"kNN\": KNeighborsClassifier(),\n",
        "        \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "        # Evaluate model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        logloss = log_loss(y_test, y_pred_proba)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        brier = brier_score_loss(y_test, y_pred_proba)\n",
        "\n",
        "        # Save results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Log Loss\": logloss,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1-Score\": f1,\n",
        "            \"ROC-AUC\": roc_auc,\n",
        "            \"Brier Score\": brier\n",
        "        }\n"
      ],
      "metadata": {
        "id": "vvV2tY_pyZ_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6r_gQGUEytmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Part 4: Ensemble Methods\n",
        "    # Voting Classifier\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', models['Logistic Regression']),\n",
        "            ('rf', models['Random Forest']),\n",
        "            ('gb', models['Gradient Boosting']),\n",
        "            ('svm', models['SVM'])\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    y_pred_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_pred_proba)\n",
        "    results['Voting Classifier'] = {\"Accuracy\": accuracy, \"Log Loss\": logloss}\n",
        "\n",
        "    # Bagging Classifier\n",
        "    bagging_clf = BaggingClassifier(estimator=models['Decision Tree'], n_estimators=50, random_state=42)\n",
        "    bagging_clf.fit(X_train, y_train)\n",
        "    y_pred_proba = bagging_clf.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_pred_proba)\n",
        "    results['Bagging'] = {\"Accuracy\": accuracy, \"Log Loss\": logloss}\n",
        "\n",
        "    # Boosting (Gradient Boosting)\n",
        "    boosting_clf = models['Gradient Boosting']\n",
        "    boosting_clf.fit(X_train, y_train)\n",
        "    y_pred_proba = boosting_clf.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_pred_proba)\n",
        "    results['Boosting'] = {\"Accuracy\": accuracy, \"Log Loss\": logloss}\n",
        "\n",
        "    # Stacking Classifier\n",
        "    stacking_clf = StackingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', models['Logistic Regression']),\n",
        "            ('rf', models['Random Forest']),\n",
        "            ('gb', models['Gradient Boosting']),\n",
        "            ('svm', models['SVM'])\n",
        "        ],\n",
        "        final_estimator=models['XGBoost']\n",
        "    )\n",
        "    stacking_clf.fit(X_train, y_train)\n",
        "    y_pred_proba = stacking_clf.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    brier = brier_score_loss(y_test, y_pred_proba)\n",
        "\n",
        "    # Save to results\n",
        "    results['Stacking'] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Log Loss\": logloss,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1,\n",
        "        \"ROC-AUC\": roc_auc,\n",
        "        \"Brier Score\": brier\n",
        "    }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qw2GwYTQytt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 5: Output Results bold text**"
      ],
      "metadata": {
        "id": "X750V8OqyD9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Convert results to DataFrame\n",
        "    results_df = pd.DataFrame(results).T\n",
        "\n",
        "    # Sort by Accuracy\n",
        "    results_df = results_df.sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "    # Print sorted results\n",
        "    print(results_df)\n",
        "\n",
        "else:\n",
        "    print(\"No data available after filtering!\")"
      ],
      "metadata": {
        "id": "bQ9TCXINzD_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}